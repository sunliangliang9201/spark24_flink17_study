！！！！！！！！！！！！！调优方向：
1.充分高效利用集群资源
2.最优的batchsize，使得processingtime与recievingtime相匹配

注：会在另一个文件中翻译所有的配置项来讲新一步理解调优问题


2.1 增加数据接收的并行度
#用多个reciver来接受行成多个dstream，然后在进行union...

2.2 增加数据处理的并行度，尤其是当设计shuffle的reduceby repartition等操作
#即使有默认的并行度，但是针对上述shuffle的操作算子可以提高并行度！！！
#提高计算并行度又可以一定程度避免OOM，因为shuffle操作会创建一个大的hashtable来保存每个task所进行的映射，可能会很大没如果增大并行的话，可以减少每个task的处理量，但是会增加task的量（注意增加task量和增加task 启动量是不一样的！！！）
#如果仅仅是相同的task，那么就可以重用，但是不同的task很多就会出现消耗大的问题

2.3 设置正确的batchinterval
#可通过观察

1.1 数据序列化
#关于数据序列化――需要设置persist的级别为mem+disk+ser来开启或者only mem+ser，rdd的默认级别是mem only，streaming的默认级别是mem only 2
是有kryo序列化类比默认的java的serialization要快很多
#优势在于：降低大量的内存消耗，因为序列化后就是每个pattion用一个byte array存储数据对象
#缺点：对对象操作的时候需要反序列化，cpu的消耗较大

1.2 降低task的启动频率

1.3 内存调优，包含DStream持久化级别；清除old data； GC
#内存消耗主要在存储data和execute data，他俩在同一区域，有默认比例划分，区别：storage mem可以随意占用、驱逐execute mem，但是execute mem只有storage mem小于阈值的时候才能去占用
#调整使用的数据结构，避免使用复杂、嵌套、多对象的数据结构，能使用int和emueration就不要用string作为key
#GC：heap size分为两个区域：Young和old区域。Young代表新的、短暂的生命周期对象，old代表着长久存在的对象
#Young分为三个区域：Eden survivor1 survivor2，eden满了 运行major GC，把eden和survivor1中存活的对象移动到survivor2中（注意survivor1 2没有区别目的是做一次过滤而已）
#当另一个survivor满的时候就进行移动到old区域，old区域接近满的时候进行full GC。
#为了避免大量的full GC和major GC，尽量提高Eden区域大小，适当减小缓存区大小spark.mem.fraction（与理想不大符合）,其实可以通过增大old mem的占比

1.4使用广播变量来床底大的变量broadcast variales

1.5 数据本地化data locality
#所谓的移动计算不移动数据
#spark自身会根据配置的timeout来觉得是否等待the better locality level


他人博客总结：
调优方向：代码调优、数据本地化、内存调优、shuffle调优、堆外内存调优、并行化调优

1.代码调优
避免创建重复的RDD，尽量使用同一个RDD
对多次使用的RDD进行缓存，缓存级别建立mem only 和 mem only ser
checkpoint的使用视情况而定
尽量避免使用shuffle类的算子，如果可以使用广播变量的方式就最好了，在本地join
尽量使用map-side渔具盒的shuffle算子：也就是有combiner的算子：reduceByKey combineByKey
尽量使用高性能算子：reducebykey替换groupbykey，原因如上述的map-combine
                    mappartition替换map
                    foreachpartition替换foreach
                    filter后使用coaleace减少分区数
                    是用repartitionandsortwithpartition替换repartition和sort操作
                    repartition和coalesce算子操作分区
使用广播变量：广播大变量发送方式：Executor一开始并没有广播变量，而是task运行需要用到广播变量，会找executor的blockManager要，bloackManager找Driver里面的blockManagerMaster要。使用广播变量可以大大降低集群中变量的副本数。不使用广播变量，变量的副本数和task数一致。使用广播变量变量的副本和Executor数一致。
使用kryo序列化：涉及序列化的有：外部变量传输、数据缓存和传输、task配送也需要，性能是默认的10倍，但是需要注册class
优化数据结构：使用string替代对象；使用int long来替代string；使用数组替代复杂的hashmap linkedlist等

2.数据本地化―― process-local node-local no-pref rack-local any五种
process-local：数据在本进程executor的内存中
node-local：在本节点磁盘上或者在本节点的其他executor内存中
no-pref：数据在关系型数据库中
rack-local：在同一个机架的node的磁盘或者executor中
any：跨机架
Spark中任务调度时，TaskScheduler在分发之前需要依据数据的位置来分发，最好将task分发到数据所在的节点上，如果TaskScheduler分发的task在默认3s依然无法执行的话，TaskScheduler会重新发送这个task到相同的Executor中去执行，会重试5次，如果依然无法执行，那么TaskScheduler会降低一级数据本地化的级别再次发送task。
可以适当调大重试次数和retry等待时间...适当哦

3.内存调优――主要考虑的是GC
问题主要是频繁的major gc和full gc问题，gc的时候会导致JVM工作线程停止
可以提高executor整体的内存大小
适当降低存储storage内存，但是要慎重

4.shuffle调优
主要是配置里面的，但是有些已经废弃了
spark.shuffle.file.buffer 32k     buffer大小 默认是32K  maptask端的shuffle 降低磁盘IO .
spark.reducer.MaxSizeFlight 48M   shuffle read拉取数据量的大小
spark.shuffle.memoryFraction 0.2  shuffle聚合内存的比例
spark.shuffle.io.maxRetries 3 拉取数据重试次数
spark.shuffle.io.retryWait 5s  调整到重试间隔时间60s
spark.shuffle.manager hash|sort   Spark Shuffle的种类
spark.shuffle.consolidateFiles false----针对HashShuffle   HashShuffle 合并机制
spark.shuffle.sort.bypassMergeThreshold 200----针对SortShuffle SortShuffle bypass机制 200次

5.executor堆外内存
spark底层shuffle的传输方式是netty传输，netty进行网络传输会申请堆外内存，默认情况这个堆外内存是executor内存大小的10%，但是如果数据量大的时候会存在频繁崩溃
调整等待时长
调整堆外内存大小：spark.executor.memory.size=2g

6.并行化
recieve并行化接收数据然后进行union为一个rdd
shuffle的时候增加并行度


