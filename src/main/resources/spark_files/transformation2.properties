map(func) = Return a new DStream by passing each element of the source DStream through a function func.
#返回一个新的DStream，其中的每个RDD都对每个元素应用map中的func函数

flatMap(func) = Similar to map, but each input item can be mapped to 0 or more output items.
#跟map类似，但是就像之前分析的，将rdd中的元素变成一个或者多个元素输出作为元素

filter(func) = Return a new DStream by selecting only the records of the source DStream on which func returns true.
#过滤函数，返回一个新的DStream，每个RDD中的元素是应用过func之后返回true的元素

repartition(numPartitions) = Changes the level of parallelism in this DStream by creating more or fewer partitions.
#重新shuffle分区，返回一个更多或者更少分区的DStream

union(otherStream) = Return a new DStream that contains the union of the elements in the source DStream and otherDStream.
#合并两个DStream

count() = Return a new DStream of single-element RDDs by counting the number of elements in each RDD of the source DStream.
#计数，返回一个DStream，但是区别在于里面的RDD中只有一个元素就是count数

reduce(func) = Return a new DStream of single-element RDDs by aggregating the elements in each RDD of the source DStream using a function func (which takes two arguments and returns one). The function should be associative and commutative so that it can be computed in parallel.
#聚合函数，返回一个新的DStream，每个RDD中的元素还是一个，但是这个是所有元素应用了reduce的func之后的一个数

countByValue() = When called on a DStream of elements of type K, return a new DStream of (K, Long) pairs where the value of each key is its frequency in each RDD of the source DStream.
#聚合函数，根据元素进行聚合，每个RDD中的元素是（k,v）形式，k唯一，value是频数

reduceByKey(func, [numTasks]) = When called on a DStream of (K, V) pairs, return a new DStream of (K, V) pairs where the values for each key are aggregated using the given reduce function. Note: By default, this uses Spark's default number of parallel tasks (2 for local mode, and in cluster mode the number is determined by the config property spark.default.parallelism) to do the grouping. You can pass an optional numTasks argument to set a different number of tasks.
#要求rdd中的元素是(k,v)形式，返回的仍然是含有(k,v)的rdds的DStream，只不过是根据key来进行聚合的，func函数的结果是v

join(otherStream, [numTasks]) = When called on two DStreams of (K, V) and (K, W) pairs, return a new DStream of (K, (V, W)) pairs with all pairs of elements for each key.
#join函数，将两个DStream进行join，结果是(k,(v1,v2))，这是内连接当然有外连接，不多说了

cogroup(otherStream, [numTasks]) = When called on a DStream of (K, V) and (K, W) pairs, return a new DStream of (K, Seq[V], Seq[W]) tuples.
#这个函数其实是两个步骤，第一步是groupbykey，第二步是join
#第一步：在DStream的rdd的内部先进行group，结果是(k,seq[v1])
#第二步：join，结果是(k,seq[v1],seq[v2])，注意还是有区别的这里结果并不是kv对，而是一个含有三个元素的tuple

transform(func) = Return a new DStream by applying a RDD-to-RDD function to every RDD of the source DStream. This can be used to do arbitrary RDD operations on the DStream.
#说白了就是方便将RDD的算子操作直接应用在DStream上

updateStateByKey(func) = Return a new "state" DStream where the state for each key is updated by applying the given function on the previous state of the key and the new values for the key. This can be used to maintain arbitrary state data for each key.
#返回一个有状态的DStream，会持续更新已有的所有key的值，这个func是关键